{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZFgIbJByODcA",
        "outputId": "84901038-526e-457c-efaa-9cfa444178ce"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow opencv-python-headless mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9Nu72m38ONtU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\strea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from cv2 import dnn\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "__BN6u54OPc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\strea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\strea\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the model from the .h5 file\n",
        "#model_path = 'faces_trained_model.h5'  # Make sure to provide the correct path\n",
        "model_path = 'Deepfake2d.h5'\n",
        "model = load_model(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nxBJ2u6zORlA"
      },
      "outputs": [],
      "source": [
        "# Load face detection model (MTCNN and SSD options)\n",
        "def load_face_detection_model(method, model_paths=None):\n",
        "    if method == 'MTCNN':\n",
        "        return MTCNN()\n",
        "    elif method == 'SSD':\n",
        "        net = dnn.readNetFromCaffe(model_paths['prototxt'], model_paths['caffemodel'])\n",
        "        return net\n",
        "    else:\n",
        "        print(\"Unsupported model for face detection.\")\n",
        "        return None\n",
        "\n",
        "# Extract frames from video (randomly select a few)\n",
        "def extract_frames_rand(video_path, num_frames_to_select):\n",
        "    capture = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    selected_frame_indices = random.sample(range(total_frames), num_frames_to_select)\n",
        "    selected_frames = []\n",
        "\n",
        "    for frame_idx in selected_frame_indices:\n",
        "        capture.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        ret, frame = capture.read()\n",
        "        if ret:\n",
        "            selected_frames.append(frame)\n",
        "\n",
        "    capture.release()\n",
        "    return selected_frames\n",
        "\n",
        "# Extract face from frame using either MTCNN or SSD\n",
        "def extract_face(frame, method='MTCNN', margin=0):\n",
        "    detector = None\n",
        "    net = None\n",
        "    if method == 'MTCNN':\n",
        "        detector = load_face_detection_model(method)\n",
        "        faces = detector.detect_faces(frame)\n",
        "        if faces:\n",
        "            x, y, w, h = faces[0]['box']\n",
        "            x -= margin\n",
        "            y -= margin\n",
        "            w += 2 * margin\n",
        "            h += 2 * margin\n",
        "            x, y, w, h = max(0, x), max(0, y), w, h\n",
        "            face = frame[y:y + h, x:x + w]\n",
        "            return cv2.resize(face, (224, 224))\n",
        "    elif method == 'SSD':\n",
        "        model_paths = {'prototxt': 'deploy.prototxt.txt', 'caffemodel': 'res10_300x300_ssd_iter_140000.caffemodel'}\n",
        "        net = load_face_detection_model(method, model_paths)\n",
        "        (h, w) = frame.shape[:2]\n",
        "        blob = dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "        net.setInput(blob)\n",
        "        detections = net.forward()\n",
        "        for i in range(0, detections.shape[2]):\n",
        "            confidence = detections[0, 0, i, 2]\n",
        "            if confidence > 0.5:\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                face = frame[startY:endY, startX:endX]\n",
        "                return cv2.resize(face, (224, 224))\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0h6ZHKNmOUSx"
      },
      "outputs": [],
      "source": [
        "# Predict deepfake or real from extracted frames\n",
        "def predict_from_frames(frames, face_detection_method='MTCNN'):\n",
        "    faces = [extract_face(frame, method=face_detection_method) for frame in frames]\n",
        "    faces = [face for face in faces if face is not None]\n",
        "\n",
        "    if not faces:\n",
        "        return [], []\n",
        "\n",
        "    faces = np.array(faces)\n",
        "    faces = preprocess_input(faces)\n",
        "\n",
        "    # Perform prediction\n",
        "    predictions = model.predict(faces)\n",
        "    return predictions, predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G3K5wMzKOXnR"
      },
      "outputs": [],
      "source": [
        "# Simulate deepfake detection from a video\n",
        "def predict_from_video(video_path, num_frames=3, face_detection_method='MTCNN'):\n",
        "    frames = extract_frames_rand(video_path, num_frames)\n",
        "    predictions, probs = predict_from_frames(frames, face_detection_method)\n",
        "\n",
        "    if len(predictions) == 0:\n",
        "        return {\"error\": \"No Faces Detected\"}, []\n",
        "\n",
        "    return format_predictions(predictions, probs)\n",
        "\n",
        "# Format predictions to be more readable\n",
        "def format_predictions(predictions, probs):\n",
        "    formatted_predictions = []\n",
        "    for prediction, prob in zip(predictions, probs):\n",
        "        label = \"Fake\" if prediction > 0.5 else \"Real\"\n",
        "        probability = prob if label == \"Fake\" else 1 - prob\n",
        "        formatted_predictions.append({\"prediction\": label, \"probability\": float(probability)})\n",
        "\n",
        "    return formatted_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCjOvwGcOYzR",
        "outputId": "11859e1d-5e2b-4286-9762-530ce7d11b64"
      },
      "outputs": [],
      "source": [
        "# Example video input path\n",
        "video_path = 'awnfpubqmo.mp4'  # Provide a path to your video file\n",
        "\n",
        "# Run deepfake detection on the video\n",
        "predictions = predict_from_video(video_path, num_frames=3, face_detection_method='MTCNN')\n",
        "\n",
        "# Print the results\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "pCG9sRtzOcPS",
        "outputId": "1ed76087-0433-4344-c194-14128bc48bfa"
      },
      "outputs": [],
      "source": [
        "# Show one of the extracted frames\n",
        "def show_image(img):\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "frames = extract_frames_rand(video_path, 1)\n",
        "show_image(frames[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QtKakevfPqGA",
        "outputId": "832f74a1-b165-4947-fe6a-7416b9d3acb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002518F915940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002518F915940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "[{'prediction': 'Fake', 'probability': 0.7104664444923401}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\strea\\AppData\\Local\\Temp\\ipykernel_20536\\2672792278.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  formatted_predictions.append({\"prediction\": label, \"probability\": float(probability)})\n"
          ]
        }
      ],
      "source": [
        "# Function to predict deepfake from an image\n",
        "def predict_from_image(image_path, face_detection=True, face_detection_method='MTCNN'):\n",
        "    # Load the image\n",
        "    frame = cv2.imread(image_path)\n",
        "    if frame is None:\n",
        "        return {\"error\": \"Image not found or unreadable\"}, []\n",
        "\n",
        "    # Perform face detection if required\n",
        "    if face_detection:\n",
        "        face = extract_face(frame, method=face_detection_method)\n",
        "        if face is None:\n",
        "            return {\"error\": \"No Face Detected\"}, []\n",
        "        face = np.expand_dims(face, axis=0)\n",
        "    else:\n",
        "        # Resize and preprocess the image without face detection\n",
        "        face = cv2.resize(frame, (224, 224))\n",
        "        face = np.expand_dims(face, axis=0)\n",
        "\n",
        "    # Preprocess the image (face or entire image)\n",
        "    face = preprocess_input(face)\n",
        "\n",
        "    # Perform prediction\n",
        "    predictions = model.predict(face)\n",
        "\n",
        "    # Format predictions\n",
        "    return format_predictions(predictions, predictions)\n",
        "\n",
        "# Example image input path\n",
        "image_path = 'img.jpg'  # Provide a path to your image file\n",
        "\n",
        "# Run deepfake detection on the image\n",
        "predictions = predict_from_image(image_path, face_detection=True, face_detection_method='MTCNN')\n",
        "\n",
        "# Print the results\n",
        "print(predictions)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
